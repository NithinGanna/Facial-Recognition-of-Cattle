{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ff0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66edc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # coding: utf-8\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import yaml\n",
    "# from yaml.loader import SafeLoader\n",
    "\n",
    "\n",
    "# class YOLO_Pred():\n",
    "#     def __init__(self,onnx_model,data_yaml):\n",
    "#         # load YAML\n",
    "#         with open(data_yaml,mode='r') as f:\n",
    "#             data_yaml = yaml.load(f,Loader=SafeLoader)\n",
    "\n",
    "#         self.labels = data_yaml['names']\n",
    "#         self.nc = data_yaml['nc']\n",
    "        \n",
    "#         # load YOLO model\n",
    "#         self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "#         self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "#         self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "        \n",
    "    \n",
    "        \n",
    "#     def predictions(self,image):\n",
    "        \n",
    "#         row, col, d = image.shape\n",
    "#         # get the YOLO prediction from the the image\n",
    "#         # step-1 convert image into square image (array)\n",
    "#         max_rc = max(row,col)\n",
    "#         input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "#         input_image[0:row,0:col] = image\n",
    "#         # step-2: get prediction from square array\n",
    "#         INPUT_WH_YOLO = 640\n",
    "#         blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    "#         self.yolo.setInput(blob)\n",
    "#         preds = self.yolo.forward() # detection or prediction from YOLO\n",
    "\n",
    "#         # Non Maximum Supression\n",
    "#         # step-1: filter detection based on confidence (0.4) and probability score (0.25)\n",
    "#         detections = preds[0]\n",
    "#         boxes = []\n",
    "#         confidences = []\n",
    "#         classes = []\n",
    "\n",
    "#         # widht and height of the image (input_image)\n",
    "#         image_w, image_h = input_image.shape[:2]\n",
    "#         x_factor = image_w/INPUT_WH_YOLO\n",
    "#         y_factor = image_h/INPUT_WH_YOLO\n",
    "\n",
    "#         for i in range(len(detections)):\n",
    "#             row = detections[i]\n",
    "#             confidence = row[4] # confidence of detection an object\n",
    "#             if confidence > 0.4:\n",
    "#                 class_score = row[5:].max() # maximum probability from 20 objects\n",
    "#                 class_id = row[5:].argmax() # get the index position at which max probabilty occur\n",
    "\n",
    "#                 if class_score > 0.25:\n",
    "#                     cx, cy, w, h = row[0:4]\n",
    "#                     # construct bounding from four values\n",
    "#                     # left, top, width and height\n",
    "#                     left = int((cx - 0.5*w)*x_factor)\n",
    "#                     top = int((cy - 0.5*h)*y_factor)\n",
    "#                     width = int(w*x_factor)\n",
    "#                     height = int(h*y_factor)\n",
    "\n",
    "#                     box = np.array([left,top,width,height])\n",
    "\n",
    "#                     # append values into the list\n",
    "#                     confidences.append(confidence)\n",
    "#                     boxes.append(box)\n",
    "#                     classes.append(class_id)\n",
    "\n",
    "#         # clean\n",
    "#         boxes_np = np.array(boxes).tolist()\n",
    "#         confidences_np = np.array(confidences).tolist()\n",
    "\n",
    "#         # NMS\n",
    "#         index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45).flatten()\n",
    "\n",
    "\n",
    "#         # Draw the Bounding\n",
    "#         for ind in index:\n",
    "#             # extract bounding box\n",
    "#             x,y,w,h = boxes_np[ind]\n",
    "#             bb_conf = int(confidences_np[ind]*100)\n",
    "#             classes_id = classes[ind]\n",
    "#             class_name = self.labels[classes_id]\n",
    "#             colors = self.generate_colors(classes_id)\n",
    "\n",
    "#             text = f'{class_name}: {bb_conf}%'\n",
    "\n",
    "#             cv2.rectangle(image,(x,y),(x+w,y+h),colors,2)\n",
    "#             cv2.rectangle(image,(x,y-30),(x+w,y),colors,-1)\n",
    "\n",
    "#             cv2.putText(image,text,(x,y-10),cv2.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)\n",
    "            \n",
    "            \n",
    "#         return image\n",
    "    \n",
    "    \n",
    "#     def generate_colors(self,ID):\n",
    "#         np.random.seed(10)\n",
    "#         colors = np.random.randint(100,255,size=(self.nc,3)).tolist()\n",
    "#         return tuple(colors[ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c2db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "\n",
    "class YOLO_Pred():\n",
    "    def __init__(self,onnx_model,data_yaml):\n",
    "        # load YAML\n",
    "        with open(data_yaml,mode='r') as f:\n",
    "            data_yaml = yaml.load(f,Loader=SafeLoader)\n",
    "\n",
    "        self.labels = data_yaml['names']\n",
    "        self.nc = data_yaml['nc']\n",
    "        \n",
    "        # load YOLO model\n",
    "        self.yolo = cv2.dnn.readNetFromONNX(onnx_model)\n",
    "        self.yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def predictions(self,image):\n",
    "        \n",
    "        row, col, d = image.shape\n",
    "        # get the YOLO prediction from the the image\n",
    "        # step-1 convert image into square image (array)\n",
    "        max_rc = max(row,col)\n",
    "        input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "        input_image[0:row,0:col] = image\n",
    "        # step-2: get prediction from square array\n",
    "        INPUT_WH_YOLO = 640\n",
    "        blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        preds = self.yolo.forward() # detection or prediction from YOLO\n",
    "\n",
    "        # Non Maximum Supression\n",
    "        # step-1: filter detection based on confidence (0.4) and probability score (0.25)\n",
    "        detections = preds[0]\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "\n",
    "        # widht and height of the image (input_image)\n",
    "        image_w, image_h = input_image.shape[:2]\n",
    "        x_factor = image_w/INPUT_WH_YOLO\n",
    "        y_factor = image_h/INPUT_WH_YOLO\n",
    "\n",
    "        for i in range(len(detections)):\n",
    "            row = detections[i]\n",
    "            confidence = row[4] # confidence of detection an object\n",
    "            if confidence > 0.4:\n",
    "                class_score = row[5:].max() # maximum probability from 20 objects\n",
    "                class_id = row[5:].argmax() # get the index position at which max probabilty occur\n",
    "\n",
    "                if class_score > 0.25:\n",
    "                    cx, cy, w, h = row[0:4]\n",
    "                    # construct bounding from four values\n",
    "                    # left, top, width and height\n",
    "                    left = int((cx - 0.5*w)*x_factor)\n",
    "                    top = int((cy - 0.5*h)*y_factor)\n",
    "                    width = int(w*x_factor)\n",
    "                    height = int(h*y_factor)\n",
    "\n",
    "                    box = np.array([left,top,width,height])\n",
    "\n",
    "                    # append values into the list\n",
    "                    confidences.append(confidence)\n",
    "                    boxes.append(box)\n",
    "                    classes.append(class_id)\n",
    "\n",
    "        # clean\n",
    "        boxes_np = np.array(boxes).tolist()\n",
    "        confidences_np = np.array(confidences).tolist()\n",
    "\n",
    "        # NMS\n",
    "#         index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45).flatten()\n",
    "        index = cv2.dnn.NMSBoxes(boxes_np, confidences_np, 0.25, 0.45)\n",
    "        index = np.array(index).flatten()\n",
    "\n",
    "        muzzle_detected = False\n",
    "        \n",
    "        # Draw the Bounding\n",
    "        for ind in index:\n",
    "            # extract bounding box\n",
    "            x,y,w,h = boxes_np[ind]\n",
    "            bb_conf = int(confidences_np[ind]*100)\n",
    "            classes_id = classes[ind]\n",
    "            class_name = self.labels[classes_id]\n",
    "            colors = self.generate_colors(classes_id)\n",
    "\n",
    "            text = f'{class_name}: {bb_conf}%'\n",
    "\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),colors,2)\n",
    "            cv2.rectangle(image,(x,y-30),(x+w,y),colors,-1)\n",
    "\n",
    "            cv2.putText(image,text,(x,y-10),cv2.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)\n",
    "            \n",
    "            if class_name== 'muzzles' or 'muzzle':\n",
    "                muzzle_detected = True\n",
    "\n",
    "\n",
    "        if muzzle_detected:\n",
    "            return image#[y:y+h, x:x+w]  # for extracting the only muzzle part  \n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    \n",
    "    def generate_colors(self,ID):\n",
    "        np.random.seed(10)\n",
    "        colors = np.random.randint(100,255,size=(self.nc,3)).tolist()\n",
    "        return tuple(colors[ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afa1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO_Pred('E:\\\\g42(cattle-proj)\\\\muzzle_yolo_predictions\\\\Model10-20231020T053132Z-001\\\\Model10\\\\weights\\\\best.onnx','E:\\g42(cattle-proj)\\muzzleCow.v2i.yolov5pytorch\\data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88acb54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"E:\\display_cows\\150\\IMG_1282.JPG\"\n",
    "\n",
    "# path='r'+ input(\"enteer path:\")\n",
    "# i = 0\n",
    "# print(path)\n",
    "# while i < len(path):\n",
    "# #     print(path[i])\n",
    "#     if path[i] == '\\\\':\n",
    "#         i = i + 1\n",
    "#         path = path[:i] + '\\\\' + path[i:]\n",
    "#     i = i + 1\n",
    "# path=path[1:]\n",
    "# print(path)\n",
    "\n",
    "\n",
    "img = cv2.imread(path)\n",
    "img = cv2.resize(img, (600,600))\n",
    "\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b01be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "# img_pred = yolo.predictions(img)\n",
    "img = yolo.predictions(img)\n",
    "# Save the modified image\n",
    "# cv2.imwrite(path, img)  # to replace the original image with extracted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43893983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('prediction image',img_pred)\n",
    "cv2.imshow('prediction image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "920e8e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter path:\"E:\\g42\\cattle_g42_crop\\161\\IMG_1401.JPG\"\n",
      "r\"E:\\g42\\cattle_g42_crop\\161\\IMG_1401.JPG\"\n",
      "\"E:\\\\g42\\\\cattle_g42_crop\\\\161\\\\IMG_1401.JPG\"\n"
     ]
    }
   ],
   "source": [
    "# to replace single \\ by double \\\\ # main working\n",
    "\n",
    "path=input(\"enter path:\")\n",
    "path='r'+path[0:]\n",
    "i = 0\n",
    "print(path)\n",
    "while i < len(path):\n",
    "#     print(path[i])\n",
    "    if path[i] == '\\\\':\n",
    "        i = i + 1\n",
    "        path = path[:i] + '\\\\' + path[i:]\n",
    "    i = i + 1\n",
    "path=path[1:]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1f0b7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\\\g42\\\\cattle_g42_crop\\\\161\\\\IMG_1401.JPG\n"
     ]
    }
   ],
   "source": [
    "# to replace single \\ by double \\\\\n",
    "\n",
    "path = r\"E:\\g42\\cattle_g42_crop\\161\\IMG_1401.JPG\"\n",
    "\n",
    "i = 0\n",
    "while i < len(path):\n",
    "    if path[i] == '\\\\':\n",
    "        i = i + 1\n",
    "        path = path[:i] + '\\\\' + path[i:]\n",
    "    i = i + 1\n",
    "print(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
